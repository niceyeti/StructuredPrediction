Global params configured
	LABELS: ABCDE
	K: 5
	XDIM: 81
	USE_TRIPLES: True
	USE_QUADS: False
Executing with  maxIt=1    R=20    eta=0.01    phiNum=2    trainPath=../nettalk_stress_train.txt    testPath=../nettalk_stress_test.txt
xdim: 81
wdim: 555
num training examples: 999
iter: 0  it-loss: 2245.0  sumCorrect: 4983.0
WARNING: TESTING ON ONLY ONE QUARTER OF THE TEST DATA, FOR FASTER TEST TIMES.
Testing weights over 249 examples. This may take a while.
Sum losses: 550  totalChars: 1672
Accuracy: 67.10526315789474%
Global params configured
	LABELS: ABCDE
	K: 5
	XDIM: 81
	USE_TRIPLES: True
	USE_QUADS: False
Executing with  maxIt=10    R=20    eta=0.01    phiNum=2    trainPath=../nettalk_stress_train.txt    testPath=../nettalk_stress_test.txt
xdim: 81
wdim: 555
num training examples: 999
iter: 0  it-loss: 2231.0  sumCorrect: 4997.0
iter: 1  it-loss: 2091.0  sumCorrect: 5137.0
iter: 2  it-loss: 2097.0  sumCorrect: 5131.0
iter: 3  it-loss: 2094.0  sumCorrect: 5134.0
iter: 4  it-loss: 2058.0  sumCorrect: 5170.0
iter: 5  it-loss: 2064.0  sumCorrect: 5164.0
iter: 6  it-loss: 2091.0  sumCorrect: 5137.0
iter: 7  it-loss: 2048.0  sumCorrect: 5180.0
iter: 8  it-loss: 2063.0  sumCorrect: 5165.0
iter: 9  it-loss: 2045.0  sumCorrect: 5183.0
WARNING: TESTING ON ONLY ONE QUARTER OF THE TEST DATA, FOR FASTER TEST TIMES.
Testing weights over 249 examples. This may take a while.
Sum losses: 486  totalChars: 1672
Accuracy: 70.93301435406698%
Global params configured
	LABELS: ABCDE
	K: 5
	XDIM: 81
	USE_TRIPLES: True
	USE_QUADS: False
Executing with  maxIt=25    R=20    eta=0.01    phiNum=2    trainPath=../nettalk_stress_train.txt    testPath=../nettalk_stress_test.txt
xdim: 81
wdim: 555
num training examples: 999
iter: 0  it-loss: 2252.0  sumCorrect: 4976.0
iter: 1  it-loss: 2097.0  sumCorrect: 5131.0
iter: 2  it-loss: 2132.0  sumCorrect: 5096.0
iter: 3  it-loss: 2142.0  sumCorrect: 5086.0
iter: 4  it-loss: 2108.0  sumCorrect: 5120.0
iter: 5  it-loss: 2105.0  sumCorrect: 5123.0
iter: 6  it-loss: 2037.0  sumCorrect: 5191.0
iter: 7  it-loss: 2019.0  sumCorrect: 5209.0
iter: 8  it-loss: 2055.0  sumCorrect: 5173.0
iter: 9  it-loss: 1990.0  sumCorrect: 5238.0
iter: 10  it-loss: 2040.0  sumCorrect: 5188.0
iter: 11  it-loss: 2029.0  sumCorrect: 5199.0
iter: 12  it-loss: 2030.0  sumCorrect: 5198.0
iter: 13  it-loss: 2074.0  sumCorrect: 5154.0
iter: 14  it-loss: 2077.0  sumCorrect: 5151.0
iter: 15  it-loss: 2074.0  sumCorrect: 5154.0
iter: 16  it-loss: 2056.0  sumCorrect: 5172.0
iter: 17  it-loss: 2038.0  sumCorrect: 5190.0
iter: 18  it-loss: 2031.0  sumCorrect: 5197.0
iter: 19  it-loss: 2084.0  sumCorrect: 5144.0
iter: 20  it-loss: 2021.0  sumCorrect: 5207.0
iter: 21  it-loss: 2071.0  sumCorrect: 5157.0
iter: 22  it-loss: 2034.0  sumCorrect: 5194.0
iter: 23  it-loss: 2086.0  sumCorrect: 5142.0
iter: 24  it-loss: 2061.0  sumCorrect: 5167.0
WARNING: TESTING ON ONLY ONE QUARTER OF THE TEST DATA, FOR FASTER TEST TIMES.
Testing weights over 249 examples. This may take a while.
Sum losses: 446  totalChars: 1672
Accuracy: 73.32535885167464%
Global params configured
	LABELS: ABCDE
	K: 5
	XDIM: 81
	USE_TRIPLES: True
	USE_QUADS: False
Executing with  maxIt=50    R=20    eta=0.01    phiNum=2    trainPath=../nettalk_stress_train.txt    testPath=../nettalk_stress_test.txt
xdim: 81
wdim: 555
num training examples: 999
iter: 0  it-loss: 2252.0  sumCorrect: 4976.0
iter: 1  it-loss: 2121.0  sumCorrect: 5107.0
iter: 2  it-loss: 2060.0  sumCorrect: 5168.0
iter: 3  it-loss: 2045.0  sumCorrect: 5183.0
iter: 4  it-loss: 2080.0  sumCorrect: 5148.0
iter: 5  it-loss: 2084.0  sumCorrect: 5144.0
iter: 6  it-loss: 2072.0  sumCorrect: 5156.0
iter: 7  it-loss: 1950.0  sumCorrect: 5278.0
iter: 8  it-loss: 2058.0  sumCorrect: 5170.0
iter: 9  it-loss: 2090.0  sumCorrect: 5138.0
iter: 10  it-loss: 2006.0  sumCorrect: 5222.0
iter: 11  it-loss: 2062.0  sumCorrect: 5166.0
iter: 12  it-loss: 2018.0  sumCorrect: 5210.0
iter: 13  it-loss: 2082.0  sumCorrect: 5146.0
iter: 14  it-loss: 2035.0  sumCorrect: 5193.0
iter: 15  it-loss: 2090.0  sumCorrect: 5138.0
iter: 16  it-loss: 2111.0  sumCorrect: 5117.0
iter: 17  it-loss: 2024.0  sumCorrect: 5204.0
iter: 18  it-loss: 2030.0  sumCorrect: 5198.0
iter: 19  it-loss: 2083.0  sumCorrect: 5145.0
iter: 20  it-loss: 2045.0  sumCorrect: 5183.0
iter: 21  it-loss: 2076.0  sumCorrect: 5152.0
iter: 22  it-loss: 2083.0  sumCorrect: 5145.0
iter: 23  it-loss: 2067.0  sumCorrect: 5161.0
iter: 24  it-loss: 2108.0  sumCorrect: 5120.0
iter: 25  it-loss: 2106.0  sumCorrect: 5122.0
iter: 26  it-loss: 2054.0  sumCorrect: 5174.0
iter: 27  it-loss: 2079.0  sumCorrect: 5149.0
iter: 28  it-loss: 2085.0  sumCorrect: 5143.0
iter: 29  it-loss: 2068.0  sumCorrect: 5160.0
iter: 30  it-loss: 2028.0  sumCorrect: 5200.0
iter: 31  it-loss: 2108.0  sumCorrect: 5120.0
iter: 32  it-loss: 1950.0  sumCorrect: 5278.0
iter: 33  it-loss: 2079.0  sumCorrect: 5149.0
iter: 34  it-loss: 2081.0  sumCorrect: 5147.0
iter: 35  it-loss: 2042.0  sumCorrect: 5186.0
iter: 36  it-loss: 2046.0  sumCorrect: 5182.0
iter: 37  it-loss: 2010.0  sumCorrect: 5218.0
iter: 38  it-loss: 2058.0  sumCorrect: 5170.0
iter: 39  it-loss: 2074.0  sumCorrect: 5154.0
iter: 40  it-loss: 2062.0  sumCorrect: 5166.0
iter: 41  it-loss: 2032.0  sumCorrect: 5196.0
iter: 42  it-loss: 2048.0  sumCorrect: 5180.0
iter: 43  it-loss: 2033.0  sumCorrect: 5195.0
iter: 44  it-loss: 1997.0  sumCorrect: 5231.0
iter: 45  it-loss: 2058.0  sumCorrect: 5170.0
iter: 46  it-loss: 2116.0  sumCorrect: 5112.0
iter: 47  it-loss: 2088.0  sumCorrect: 5140.0
iter: 48  it-loss: 2078.0  sumCorrect: 5150.0
iter: 49  it-loss: 2081.0  sumCorrect: 5147.0
WARNING: TESTING ON ONLY ONE QUARTER OF THE TEST DATA, FOR FASTER TEST TIMES.
Testing weights over 249 examples. This may take a while.
Sum losses: 479  totalChars: 1672
Accuracy: 71.35167464114834%
Global params configured
	LABELS: ABCDE
	K: 5
	XDIM: 81
	USE_TRIPLES: True
	USE_QUADS: False
Executing with  maxIt=100    R=20    eta=0.01    phiNum=2    trainPath=../nettalk_stress_train.txt    testPath=../nettalk_stress_test.txt
xdim: 81
wdim: 555
num training examples: 999
iter: 0  it-loss: 2295.0  sumCorrect: 4933.0
iter: 1  it-loss: 2098.0  sumCorrect: 5130.0
iter: 2  it-loss: 2084.0  sumCorrect: 5144.0
iter: 3  it-loss: 2091.0  sumCorrect: 5137.0
iter: 4  it-loss: 2052.0  sumCorrect: 5176.0
iter: 5  it-loss: 2110.0  sumCorrect: 5118.0
iter: 6  it-loss: 2058.0  sumCorrect: 5170.0
iter: 7  it-loss: 2106.0  sumCorrect: 5122.0
iter: 8  it-loss: 2047.0  sumCorrect: 5181.0
iter: 9  it-loss: 2026.0  sumCorrect: 5202.0
iter: 10  it-loss: 2038.0  sumCorrect: 5190.0
iter: 11  it-loss: 2022.0  sumCorrect: 5206.0
iter: 12  it-loss: 2017.0  sumCorrect: 5211.0
iter: 13  it-loss: 2054.0  sumCorrect: 5174.0
iter: 14  it-loss: 2096.0  sumCorrect: 5132.0
iter: 15  it-loss: 2039.0  sumCorrect: 5189.0
iter: 16  it-loss: 2045.0  sumCorrect: 5183.0
iter: 17  it-loss: 2092.0  sumCorrect: 5136.0
iter: 18  it-loss: 1989.0  sumCorrect: 5239.0
iter: 19  it-loss: 2100.0  sumCorrect: 5128.0
iter: 20  it-loss: 2046.0  sumCorrect: 5182.0
iter: 21  it-loss: 2096.0  sumCorrect: 5132.0
iter: 22  it-loss: 2042.0  sumCorrect: 5186.0
iter: 23  it-loss: 2043.0  sumCorrect: 5185.0
iter: 24  it-loss: 2029.0  sumCorrect: 5199.0
iter: 25  it-loss: 2030.0  sumCorrect: 5198.0
iter: 26  it-loss: 2036.0  sumCorrect: 5192.0
iter: 27  it-loss: 2040.0  sumCorrect: 5188.0
iter: 28  it-loss: 2040.0  sumCorrect: 5188.0
iter: 29  it-loss: 2016.0  sumCorrect: 5212.0
iter: 30  it-loss: 2014.0  sumCorrect: 5214.0
iter: 31  it-loss: 2026.0  sumCorrect: 5202.0
iter: 32  it-loss: 2073.0  sumCorrect: 5155.0
iter: 33  it-loss: 2011.0  sumCorrect: 5217.0
iter: 34  it-loss: 2058.0  sumCorrect: 5170.0
iter: 35  it-loss: 2015.0  sumCorrect: 5213.0
iter: 36  it-loss: 2100.0  sumCorrect: 5128.0
iter: 37  it-loss: 2047.0  sumCorrect: 5181.0
iter: 38  it-loss: 2093.0  sumCorrect: 5135.0
iter: 39  it-loss: 2150.0  sumCorrect: 5078.0
iter: 40  it-loss: 2024.0  sumCorrect: 5204.0
iter: 41  it-loss: 2023.0  sumCorrect: 5205.0
iter: 42  it-loss: 2049.0  sumCorrect: 5179.0
iter: 43  it-loss: 2061.0  sumCorrect: 5167.0
iter: 44  it-loss: 2012.0  sumCorrect: 5216.0
iter: 45  it-loss: 2027.0  sumCorrect: 5201.0
iter: 46  it-loss: 2039.0  sumCorrect: 5189.0
iter: 47  it-loss: 2043.0  sumCorrect: 5185.0
iter: 48  it-loss: 2084.0  sumCorrect: 5144.0
iter: 49  it-loss: 2074.0  sumCorrect: 5154.0
iter: 50  it-loss: 2051.0  sumCorrect: 5177.0
iter: 51  it-loss: 2037.0  sumCorrect: 5191.0
iter: 52  it-loss: 2059.0  sumCorrect: 5169.0
iter: 53  it-loss: 2065.0  sumCorrect: 5163.0
iter: 54  it-loss: 2059.0  sumCorrect: 5169.0
iter: 55  it-loss: 2090.0  sumCorrect: 5138.0
iter: 56  it-loss: 2071.0  sumCorrect: 5157.0
iter: 57  it-loss: 2132.0  sumCorrect: 5096.0
iter: 58  it-loss: 2113.0  sumCorrect: 5115.0
iter: 59  it-loss: 2117.0  sumCorrect: 5111.0
iter: 60  it-loss: 2052.0  sumCorrect: 5176.0
iter: 61  it-loss: 2085.0  sumCorrect: 5143.0
iter: 62  it-loss: 2050.0  sumCorrect: 5178.0
iter: 63  it-loss: 2048.0  sumCorrect: 5180.0
iter: 64  it-loss: 2020.0  sumCorrect: 5208.0
iter: 65  it-loss: 1933.0  sumCorrect: 5295.0
iter: 66  it-loss: 2049.0  sumCorrect: 5179.0
iter: 67  it-loss: 2108.0  sumCorrect: 5120.0
iter: 68  it-loss: 2066.0  sumCorrect: 5162.0
iter: 69  it-loss: 2100.0  sumCorrect: 5128.0
iter: 70  it-loss: 2065.0  sumCorrect: 5163.0
iter: 71  it-loss: 2073.0  sumCorrect: 5155.0
iter: 72  it-loss: 2098.0  sumCorrect: 5130.0
iter: 73  it-loss: 2119.0  sumCorrect: 5109.0
iter: 74  it-loss: 2048.0  sumCorrect: 5180.0
iter: 75  it-loss: 2062.0  sumCorrect: 5166.0
iter: 76  it-loss: 2076.0  sumCorrect: 5152.0
iter: 77  it-loss: 1997.0  sumCorrect: 5231.0
iter: 78  it-loss: 2036.0  sumCorrect: 5192.0
iter: 79  it-loss: 2039.0  sumCorrect: 5189.0
iter: 80  it-loss: 2052.0  sumCorrect: 5176.0
iter: 81  it-loss: 2065.0  sumCorrect: 5163.0
iter: 82  it-loss: 2103.0  sumCorrect: 5125.0
iter: 83  it-loss: 2011.0  sumCorrect: 5217.0
iter: 84  it-loss: 2036.0  sumCorrect: 5192.0
iter: 85  it-loss: 2057.0  sumCorrect: 5171.0
iter: 86  it-loss: 2080.0  sumCorrect: 5148.0
iter: 87  it-loss: 1952.0  sumCorrect: 5276.0
iter: 88  it-loss: 2021.0  sumCorrect: 5207.0
iter: 89  it-loss: 2072.0  sumCorrect: 5156.0
iter: 90  it-loss: 2067.0  sumCorrect: 5161.0
iter: 91  it-loss: 2075.0  sumCorrect: 5153.0
iter: 92  it-loss: 2018.0  sumCorrect: 5210.0
iter: 93  it-loss: 2075.0  sumCorrect: 5153.0
iter: 94  it-loss: 2019.0  sumCorrect: 5209.0
iter: 95  it-loss: 2041.0  sumCorrect: 5187.0
iter: 96  it-loss: 2072.0  sumCorrect: 5156.0
iter: 97  it-loss: 1998.0  sumCorrect: 5230.0
iter: 98  it-loss: 2075.0  sumCorrect: 5153.0
iter: 99  it-loss: 2017.0  sumCorrect: 5211.0
WARNING: TESTING ON ONLY ONE QUARTER OF THE TEST DATA, FOR FASTER TEST TIMES.
Testing weights over 249 examples. This may take a while.
Sum losses: 482  totalChars: 1672
Accuracy: 71.17224880382776%
